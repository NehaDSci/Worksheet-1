{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING‚Äì WORKSHEET 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The computational complexity of linear regression is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " D)   O(n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which of the following can be used to fit non-linear data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)     Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Which of the following can be used to optimize the cost function of Linear Regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B)    Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which of the following method does not have closed form solution for its coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)     Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Which gradient descent algorithm always gives optimal solution? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D)      All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generalization error measures how well a model performs on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A)     True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. The cost function of linear regression can be given as  ùêΩ(ùë§0,ùë§1)=1/2ùëö‚àëm i=1 (ùë§0 + ùë§1ùë•(ùëñ) ‚àí ùë¶(ùëñ))2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)     it does not matter whether half is there or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Which of the following will have symmetric relation between dependent variable and independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)      Both of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Which of the following is true about Normal Equation used to compute the coefficient of the Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A)        We don‚Äôt have to choose the learning rate.\n",
    "B)       It becomes slow when number of features are very large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 10. Which of the following statement/s are true if we generated data with the help of polynomial features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A)        Linear Regression will have high bias and low variance.\n",
    "D)       Polynomial with degree 5 will have high bias and low variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Which of the following sentence is false regarding regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)     It discovers causal relationship.\n",
    "D)     No inference can be made from regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Which Linear Regression training algorithm can we use if we have a training set with millions of features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch gradient descent, stochastic gradient descent or mini-batch gradient descent. It doest not need to load the entire dataset into memory \n",
    "for taking 1st step of gradient descent. Batch gradient descent is used when it have enough memory to load all data. But Normal equations method\n",
    "cannot be used because computational complexity grows very quickly with number of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Which algorithms will not suffer or might suffer, if the features in training set have very different scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal equations method does not require normalizing the features, so it remains unaffected by features in the training set having \n",
    "very diffent scales. Features scaling is required for the various gradient descent algorithms. feature scaling will help gradient descent coverge quicker.\n",
    "The cost function will have the shape of an elongated bowl, so the Gradient Descent Algorithms will take a long to converge. To solve this you should \n",
    "scale the data before training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
